import argparse
import textwrap

def parse_argument(sys_argv):
    """Parses arguments from command line.

    Args:
        sys_argv: the list of arguments (strings) from command line.

    Returns:
        A struct whose member corresponds to the required (optional) variable.
        For example,
        ```
        args = parse_argument(['main.py' '--input', 'a.txt', '--num', '10'])
        args.input       # 'a.txt'
        args.num         # 10
        ```
    """
    parser = argparse.ArgumentParser(
        formatter_class=argparse.RawTextHelpFormatter,
        description='Deep learning models for image classification')

    # Training parameters

    parser.add_argument(
        '--train-data', type=str, required=True,
        help=textwrap.dedent(
            '''
            Train data path
            '''))
    parser.add_argument(
        '--val-data', type=str, required=True,
        help=textwrap.dedent(
            '''
            Validation data path
            '''))
    parser.add_argument(
        '--test-data', type=str, required=True,
        help=textwrap.dedent(
            '''
            Test data path
            '''))

    parser.add_argument(
        '--num_dataload_worker', type=int,
        default=4,
        help='number of dataloader workers'
    )

    parser.add_argument(
        '--train_sample_percentage', type=float, default=0.9,
        help='First {train_sample_percentage} in the training set are used for training')

    parser.add_argument(
        '--validation_sample_percentage', type=float, default=0.1,
        help='Last {validation_sample_percentage} in the training set are used for validation')

    parser.add_argument(
        '--disable_validation_shuffle', action='store_true',
        help='Turn off validation set (for training) shuffle')

    parser.add_argument(
        '--use_test_transform_for_train', action='store_true',
        help='Use test augmentation for train augmentation')

    parser.add_argument(
        '--optimizer', type=str, default='name=sgd, momentum=0.0',
        help=textwrap.dedent(
            '''
            Supported optimizer OPTIM (specified by name=OPTIM):
              1) "sgd"
              2) "adagrad"
              3) "adam"
              4) "adamw"
            Syntax:
              "name=OPTIM, ..." # followed by optimizer-based arguments
            '''))

    parser.add_argument(
        '--lr_scheduler', type=str, default='name=cosine, min_lr=0.0',
        help=textwrap.dedent(
            '''
            Supported optimizer OPTIM (specified by name=OPTIM):
              1) "cosine" for cosine decay scheduler. Args:
                  - min_lr: minimum lr of cosine decay.
              2) "exponential" for exponential decay scheduler. Args:
                  - min_lr: minimum lr of exponential decay.
            Syntax:
              "name=OPTIM, ..." # followed by scheduler-based arguments
            '''))

    parser.add_argument(
        '--regularizer_fixed_init', type=float, default=None,
        help=textwrap.dedent(
            '''
            Initial regularizer value (fixed). None by default, which will
            initializes all regularizer parameters from uniform distribution
            [0, 0.01).
            '''
        ))
    parser.add_argument(
        '--regularizer_grad_norm_clip', type=float, default=None,
        help='Gradient norm clip value for regularizer params. No clip by default.')
    parser.add_argument(
        '--regularizer_param_clamp', type=float, default=None,
        help='Parameter clamp max value for regularizer. No clamp by default.')
    parser.add_argument(
        '--validation_model_mode', type=str, default='train',
        choices=['train', 'eval'],
        help='The model mode (model.train/model.eval) during validation training'
    )

    # parser.add_argument(
    #     '--device', type=str, required=True,
    #     help=textwrap.dedent(
    #         '''
    #         Supported devices:
    #           1) "cpu"
    #           2) "gpu"
    #         '''))
    parser.add_argument(
        '--sampler', type=str, required=True,
        help=textwrap.dedent(
            '''
            Supported samplers:
              1) "full"
                The full dataset is used for computing, used by GD.

              2) "stochastic"
                `args.batch_size` random samples are generated by directly
                obtaining the next batch of dataset, used by SGD.
            '''
        ))

    parser.add_argument(
        '--init_alpha', type=float, default=0.03,
        help='initial alpha')
    parser.add_argument(
        '--init_lr', type=float, required=True,
        help='Initial learning rate')
    parser.add_argument(
        '--tau', type=float, default=2,
        help='alpha *= tau every outer iteration')
    parser.add_argument(
        '--num_outer_iter', type=int, default=1,
        help='The number of outer iterations')
    parser.add_argument(
        '--num_inner_iter', type=int, default=None,
        help='The number of outer iterations')
    parser.add_argument(
        '--epoch', type=int, default=3,
        help='The number of epochs')
    parser.add_argument(
        '--global_batch_size', type=int, required=True, default=1,
        help='Global batch size')

    parser.add_argument(
        '--micro_batch_size', type=int, required=True, default=1,
        help='Micro batch size')

    parser.add_argument(
        '--val_batch_size', type=int, default=4,
        help='Val micro batch size')

    # Model parameters
    parser.add_argument(
        '--model', type=str, default='googlenet',
        help=textwrap.dedent(
            '''
            Supported models:
              * linear
              * alexnet
              * resnet18
              * resnet50
              * googlenet
              * vgg11_bn
              * vgg13_bn
              * vgg16
              * vgg16_bn
              * vgg19_bn
              * hyperresnet18
                (For the purpose of aligning settings with bilevel baselines)
            '''))
    parser.add_argument(
        '--tokenizer-name', type=str, default=None,)
    
    parser.add_argument(
        '--bf16', action='store_true',
        help='Whether use bf16 training')
    
    parser.add_argument(
        '--lora', action='store_true',
        help='Whether use LoRA training')
    parser.add_argument(
        '--lisa', action='store_true',
        help='Whether use Lisa training')
    parser.add_argument(
        '--lisa-step', type=int, default=20,
        help='Lisa step')
    # Test parameters
    parser.add_argument(
        '--eval_frequency', type=int, default=1000000,
        help='Evaluate every {eval_frequency} inner iterations')

    # Debug parameters
    parser.add_argument(
        '--seed', type=int, default=23,
        help='Random seed that controls the pseudo-random behavior')
    parser.add_argument(
        '--pseudo_random', const=True, default=False, nargs='?',
        help='A global option to make all random operations deterministic')
    parser.add_argument(
        '--logging_conf_file', default='conf/common.log_conf', type=str,
        help='The configuration file for logging')
    parser.add_argument(
        '--use_wandb', action='store_true',
        help='Turn on wandb logging',
    )
    parser.add_argument(
        '--wandb_project', type=str, default='bilevel-optimization',
        help='Project name for wandb',
    )
    parser.add_argument(
        '--wandb_run_name', type=str, default=None,
        help='Run name for wandb',
    )
    parser.add_argument(
        '--save_dir', default=None, type=str,
        help='Where to save the model')
    # Algorithm-dependent parameters
    parser.add_argument(
        '--minmax_validation_sampler',
        type=str,
        default=None,
        choices=[None, 'full', 'stochastic'],
        help=textwrap.dedent(
            '''
            A separated sampler for validation loss during training of minmax.
            By default the validation samplers is the same as the global sampler
            `--sampler`.
            '''
        ))
    # parser.add_argument(
    #     '--minmax_validation_batch_size',
    #     type=int,
    #     default=None,
    #     help=textwrap.dedent(
    #         '''
    #         A separated batch size for validatiohn loss during training of
    #         minmax. By default the validation batch size is the same as the
    #         global batch size `--batch_size`.
    #         '''
    #     ))
    parser.add_argument(
        '--minmax_init_lr_w',
        type=float,
        default=None,
        help=textwrap.dedent(
            '''
            Initial learning rate for omega (w). None by default, whose value
            will be set to `args.init_lr`.
            '''
        )
    )
    parser.add_argument(
        '--minmax_init_lr_u',
        type=float,
        default=None,
        help=textwrap.dedent(
            '''
            Initial learning rate for u. None by default, whose value
            will be set to `args.init_lr`.
            '''
        )
    )
    parser.add_argument(
        '--minmax_init_lr_lambda',
        type=float,
        default=None,
        help=textwrap.dedent(
            '''
            Initial learning rate for lambda. None by default, whose value
            will be set to `args.init_lr`.
            '''
        )
    )
    parser.add_argument(
        '--num_partitions', type=int,
        default=10,
        help='number of partitions'
    )
    parser.add_argument(
        '--max-length', type=int,
        default=256,
        help='number of partitions'
    )
    parser.add_argument(
        '--model-type', type=str,
        default='llama',
        help='llama/gpt2'
    )
    parser.add_argument(
        '--response_loss_only', action='store_true',
        help='Only use loss of response'
    )
    parser.add_argument(
        '--sharegpt_format', action='store_true',
        help='Only use loss of response'
    )

    parser.add_argument(
        '--pretrain', action='store_true',
        help='Pretrain mode'
    )
    # Parses from commandline
    args = parser.parse_args(sys_argv[1:])

    return args


def parse_args_dict(args_string):
    """Parses strings like 'type=sgd, momentum=0.0, nesterov=True'.

    Returns:
        A dict mapping names to their values, e.g.
        {
            'type': 'sgd',
            'momentum': 0.0,
            'nesterov': True,
        }
    """
    args_string = args_string.replace(' ', '').replace(',', '\n')
    args_string = "[model_args]\n" + args_string

    import configparser
    import io
    import ast

    # Uses config parser to parse the input string, the result dict has values
    # with str types
    buf = io.StringIO(args_string)
    config = configparser.ConfigParser()
    config.read_file(buf)

    args_dict = { s: dict(config.items(s)) for s in config.sections() }

    # Use .liter_eval to decide types of the value, e.g. 0.0 -> float, True ->
    # bool
    new_args_dict = {}
    for k, v in args_dict['model_args'].items():
        try:
            tmp_v = ast.literal_eval(v)
            new_args_dict[k] = tmp_v
        except:
            new_args_dict[k] = v
            continue

    return new_args_dict